# Consolidated list of projects:

### Netscribes Data & Insights Pvt Ltd
|Sr. No.|	Project/Task|	Description| Skills/Tools|
|-------|-------------|------------|-------------|
|1|	NLP Analytics | End-to-end data analysis solution with NER, Topic Modelling, Sentiment Analysis, and Dashboarding for E-commerce reviews and surveys| Python, Spacy, Scikit-Learn, PowerBI	|
|2| Data Engineering | Data Ingestion and Transformation pipeline on Databricks using Delta Lake. Applying custom transformations for analysis/reporting (following a Medallion Architecture) | Python, PySpark, Databricks, AirByte	|
|3| Audio Video Analytics | Advanced video and audio analytics for validating influencer promotions using Computer Vision Object Detection and transcription models. Optimized image processing pipeline implementation using PySpark | Databricks, PySpark, Delta Lake, Detecto (CV model), OpenAi Whisper |
|4| PDF Image analysis and Information retrieval | Extraction of Graph Images and text from PDF, detecting graphs/plots and analyzing detected information, performing NER on the textual data, API integration with an internal workflow tool, facilitating complete automation  | Object Detection Model, Spacy NER, Python, NSWorkflow, Fastapi, AWS Textract |
|5| Lead Conversion & Renewal Engagement POC | Analysing data sources, shortlisting sources w.r.t. use cases, data transformation/pre-processing, data modeling, EDA, Feature selection and engineering, correlation testing. | Databricks, Delta Lake, SQL, Python |  


### Mahindra Integrated Business Solutions
|Sr. No.|	Project/Task|	Description| Skills/Tools|
|-------|-------------|------------|-------------|
|1|	Athena|1.1)	Analytics Chatbot based on DialogFlow, NodeJs and Python capable of answering complex questions (Text,Tables and Charts)|	NodeJs, Python GroupBys, DialogFlow|
|	|	|1.2) Conversation History Dashboard to view, analyze, filter, comment action items and download csv.|	Flask, MS SQL Server, DB CRUD Operations, HTML, CSS, Javascript|
|2|	NewsApp| 2.1) Multiple Crawlers for scraping multiple news sites, cleaning data, summarizing and inserting in DB.|	Scrapy, MongoDb, extracting data from APIs/Javascripts|
| |	|2.2) A Multipage WebApp to View, Edit, Download News in Template. Features: [ Recommendations, Sorting and  Filtering by Date/Keywords/Countries/Sources, Adding/Removing keywords, List view, Drag & Drop for bucketing, Download Article in Defined Template]|	Django, Mongo DB, DB CRUD Operations, HTML, CSS, Javascript|
|3|	ITM-Skill Validation|	A portal to upload an excel file, convert rows to pages, display stats per page, edit & update/insert data into DB, download updated excel file.|	Flask, MS SQL Server, DB CRUD Operations, HTML, CSS, Javascript|
|4|	LMS UI|	A Demo UI for displaying courses recommended. To consume LMS Recommendation REST Api and display data.|	Django, HTML, CSS|
|5|	Small Utilities|	Many small utilities and APIs as ad-hoc support for different applications like authentication/authorization, rule based chatbot, bot UI, consuming APIs, Data transformation pipelines, etc.|	Python, Fastapi, MS SQL Server, Flask, etc.|

<br/>

### Convergence IT Services
|Sr. No.|	Project/Task|	Description| Skills/Tools|
|-------|-------------|------------|-------------|
|1|	Marksheet OCR|	It automated the document verification process by extracting data from scanned documents and validating it with the scraped data from official government websites. Basically it is combination of an OCR Project and Web Scraping (with captcha verification).| 	AWS Textract, Json, Flask, Regex|
|2|	Text Summarization|	This was an abstractive summarization algorithm from scrath. It was built by following the tensorflow's NMT approach. |	Tensorflow backend Keras Functional API, tf, Sequence to Sequence models, NLP, Neural Networks, RNN, LSTM, attention model, saving models, word embeddings, vocab, NMT.|
|3|	Fault Prediction POC|	In this POC we proposed a model to predict alarms on different Networking devices. The output from this model helped us to get the probability of any specific event occurring on any specific node within a specific time interval. The prediction output consists of the following: name of the Source Node, the dates for which the predictions are made, historical window and alarm labels with respective probabilities of occurrence. We implemented a research paper which proposed a sliding window approach by designing custom data transformation pipelines.|	Data Cleaning, Transformation, EDA, reading Research Papers, Co-ordinating with stake holders, Python, Numpy, Pandas, RFC, SVC, XGB, create testing pipeline.|
|4|	Document OCR|	A robust combination of Document Classification model and OCR Pipeline. The Document Classifier itself was ensemble of Image Classification and Text Classification. The Input data consisted of PNG, JPG, text based PDF, Scanned Image PDF, DOC, etc. data formats and 10 different classes like Purchase orders, AWB, Tax Invoices, etc. After successful classification, text data gets extracted by either pdf parsing, doc parsing or AWS Textract.|	Document classification, Text Classification, Image Classification, TF-IDF, CNN, OCR (Tesseract), AWS Textract, Rest Api.|
|5|	Aadhaar + Pan OCR|	A simple project to extract data from Aadhaar card and PAN card by using Google Vision for OCR.|	Google Vision, Json, Flask, Regex|

<br/>

### Apptroid Technology
|Sr. No.|	Project/Task|	Description| Skills/Tools|
|-------|-------------|------------|-------------|
|1|	Data Cleaning|	Cleaning address data, filtering upto granular level (state/city/town/district)|	Affinity Propagation Clustering, Algolia Places Api, Pandas, Regex|
|2|	Descriptive Analysis|	Basic Descriptive analysis of client app data.|	Pandas, matplotlib, seaborn, excel|

<br/>
